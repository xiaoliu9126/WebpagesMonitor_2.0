[{"subject": "Number of created processes", "time": "Monday, 28 December 2020, 4:35 PM", "context": "\nHello Dr Saeid/ Dr Qian,In questions related to fork(), if we are asked how many processes are created, do we count all processes including the parent process? Or only the child processes excluding the parent? Thank you!\n"}, {"subject": "Number of created processes", "time": "Monday, 28 December 2020, 4:35 PM", "context": "\nHello Dr Saeid/ Dr Qian,In questions related to fork(), if we are asked how many processes are created, do we count all processes including the parent process? Or only the child processes excluding the parent? Thank you!\n"}, {"subject": "About SCAN algorithm calculation", "time": "Monday, 28 December 2020, 4:14 PM", "context": "\nSCAN would go to the last and first cylinder in its journey according to the slides.\"When it gets to the last cylinder, it reverses direction and services all the pending requests (until it reaches the first cylinder)\"However, the calculation \"(for 11 1 36 16 34 9 12): |11-12|+|1216|+|16-34|+|34-36|+|36-9|+|9-1|=60\" in slide (lec22 24) does not go to the last one either the first one (0). I noticed in the exam paper, tracks ID is always given as like (0:79). Does it mean we need to suppose the head goes to the last and first or just calculate like the slides?same question for CSCAN.\n"}, {"subject": "About SCAN algorithm calculation", "time": "Monday, 28 December 2020, 4:14 PM", "context": "\nSCAN would go to the last and first cylinder in its journey according to the slides.\"When it gets to the last cylinder, it reverses direction and services all the pending requests (until it reaches the first cylinder)\"However, the calculation \"(for 11 1 36 16 34 9 12): |11-12|+|1216|+|16-34|+|34-36|+|36-9|+|9-1|=60\" in slide (lec22 24) does not go to the last one either the first one (0). I noticed in the exam paper, tracks ID is always given as like (0:79). Does it mean we need to suppose the head goes to the last and first or just calculate like the slides?same question for CSCAN.\n"}, {"subject": "Question about increasing CPU utilization", "time": "Monday, 28 December 2020, 3:30 PM", "context": "\nThere are several methods to increase CPU utilization including ones who are likely to result in an increase. In such case, should we treat it as a method who could increase CPU utilization?\n"}, {"subject": "Question about increasing CPU utilization", "time": "Monday, 28 December 2020, 3:30 PM", "context": "\nThere are several methods to increase CPU utilization including ones who are likely to result in an increase. In such case, should we treat it as a method who could increase CPU utilization?\n"}, {"subject": "Questions about the dining philosophers problem", "time": "Monday, 28 December 2020, 11:19 AM", "context": "\nI'm wondering if the final examination may include the dining philosophers problem mentioned in lecture 12.\n"}, {"subject": "Questions about the dining philosophers problem", "time": "Monday, 28 December 2020, 11:19 AM", "context": "\nI'm wondering if the final examination may include the dining philosophers problem mentioned in lecture 12.\n"}, {"subject": "Questions about mutual exclusion", "time": "Sunday, 27 December 2020, 7:24 PM", "context": "\nIn lecture 7 & 8, one quiz asks that if a single-processor system needs to consider mutual exclusion, and the answer provided is \"No if it is non-preemptive\".However, if a process executing in the critical section blocks (for example, the process makes a system call to read from a shared file) and the short-term scheduler decides to run another process, the new process will have a possibility to enter the critical section. Considering this scenario, mutual exclusion should also be considered and guaranteed even on a non-preemptive single-processor system.\n"}, {"subject": "Questions about mutual exclusion", "time": "Sunday, 27 December 2020, 7:24 PM", "context": "\nIn lecture 7 & 8, one quiz asks that if a single-processor system needs to consider mutual exclusion, and the answer provided is \"No if it is non-preemptive\".However, if a process executing in the critical section blocks (for example, the process makes a system call to read from a shared file) and the short-term scheduler decides to run another process, the new process will have a possibility to enter the critical section. Considering this scenario, mutual exclusion should also be considered and guaranteed even on a non-preemptive single-processor system.\n"}, {"subject": "Question about File lecture 3 quiz 2", "time": "Sunday, 27 December 2020, 5:45 PM", "context": "\nIn lecture 24 the quiz question 2, according to the answer you provided, only FAT needs additional main memory space. I'm not sure about the word \"additional\". I understand that the file allocation tables are always needed to be stored in the main memory. However, in my understanding, i-nodes may also need the main memory space when the corresponding file is open. In addition, a certain much space needs to be reserved in the main memory in advance according to the maximum number of the file that may be open, and the size of each i-node occupying. I wonder why this using of main memory is not considering as the additional main memory space. Looking forward to your clarification.\n"}, {"subject": "Question about File lecture 3 quiz 2", "time": "Sunday, 27 December 2020, 5:45 PM", "context": "\nIn lecture 24 the quiz question 2, according to the answer you provided, only FAT needs additional main memory space. I'm not sure about the word \"additional\". I understand that the file allocation tables are always needed to be stored in the main memory. However, in my understanding, i-nodes may also need the main memory space when the corresponding file is open. In addition, a certain much space needs to be reserved in the main memory in advance according to the maximum number of the file that may be open, and the size of each i-node occupying. I wonder why this using of main memory is not considering as the additional main memory space. Looking forward to your clarification.\n"}, {"subject": "Deadlock question", "time": "Sunday, 27 December 2020, 1:40 AM", "context": "\n                            For deadlock detection part, there introduces a Graph Based Approach. In the slide, it said that \"In case that only a single resource exists per type , a graph approach can be used\" So I wonder in the exam, if there is some question dealing with graph approach, would there be some cases when multiple resources are depicted. For example, like the graph below displayed. (There are multiple entities in one kind of resource: r2 and r5)Thanks!\n"}, {"subject": "Deadlock question", "time": "Sunday, 27 December 2020, 1:40 AM", "context": "\n                            For deadlock detection part, there introduces a Graph Based Approach. In the slide, it said that \"In case that only a single resource exists per type , a graph approach can be used\" So I wonder in the exam, if there is some question dealing with graph approach, would there be some cases when multiple resources are depicted. For example, like the graph below displayed. (There are multiple entities in one kind of resource: r2 and r5)Thanks!\n"}, {"subject": "A Question about Fixed non-equal sized partition", "time": "Saturday, 26 December 2020, 11:45 AM", "context": "\nThis is a question related to Memory Management Techniques.In Lecture13, slide 23, it is said that \"A single shared queue\" for all partitions can allocate small processes to large partitions. However in Stallings' book on page 347, it is said that \"When it is time to load a process into main memory, the smallest available partition that will hold the process is selected\", in this case, how could a process be allocated to a partition that has a bigger memory than the smallest partition to fit the process? And how the \"Single shared queue\" result in increased internal fragmentation?Besides, in Lecture13, slide 21, it is said that a fixed non-equal sized partition reduces internal fragmentation generally, so does it work for both \"One process queue per partition\" and \"Single shared queue\"?\n"}, {"subject": "A Question about Fixed non-equal sized partition", "time": "Saturday, 26 December 2020, 11:45 AM", "context": "\nThis is a question related to Memory Management Techniques.In Lecture13, slide 23, it is said that \"A single shared queue\" for all partitions can allocate small processes to large partitions. However in Stallings' book on page 347, it is said that \"When it is time to load a process into main memory, the smallest available partition that will hold the process is selected\", in this case, how could a process be allocated to a partition that has a bigger memory than the smallest partition to fit the process? And how the \"Single shared queue\" result in increased internal fragmentation?Besides, in Lecture13, slide 21, it is said that a fixed non-equal sized partition reduces internal fragmentation generally, so does it work for both \"One process queue per partition\" and \"Single shared queue\"?\n"}, {"subject": "Questions about memory access time using TLB and multi-level page tables", "time": "Thursday, 24 December 2020, 4:02 PM", "context": "\n                            I'm wondering if each entry of the TLB always stores the page number and the actual corresponding frame number no matter how many levels of page tables we use, i.e. the memory access time when TLB hit happens is always 20 + 100 ns (assuming the TLB lookup time is 20 ns and the memory access time is 100 ns).\n                        "}, {"subject": "Questions about memory access time using TLB and multi-level page tables", "time": "Thursday, 24 December 2020, 4:02 PM", "context": "\n                            I'm wondering if each entry of the TLB always stores the page number and the actual corresponding frame number no matter how many levels of page tables we use, i.e. the memory access time when TLB hit happens is always 20 + 100 ns (assuming the TLB lookup time is 20 ns and the memory access time is 100 ns).\n                        "}, {"subject": "A question about the Performance evaluation of TLBs", "time": "Wednesday, 23 December 2020, 3:17 PM", "context": "\nHi Professors.In lecture 16 p18 it says that the Performance evaluation of TLBs:  For an 80% hit rate. the estimated access time is: 120×0.8+220×(1−0.8) = 140ns (i.e. 40% slowdown) Why it is 40% slowdown instead of (140-120)/120*100%?\n"}, {"subject": "A question about the Performance evaluation of TLBs", "time": "Wednesday, 23 December 2020, 3:17 PM", "context": "\nHi Professors.In lecture 16 p18 it says that the Performance evaluation of TLBs:  For an 80% hit rate. the estimated access time is: 120×0.8+220×(1−0.8) = 140ns (i.e. 40% slowdown) Why it is 40% slowdown instead of (140-120)/120*100%?\n"}, {"subject": "Two questions ", "time": "Wednesday, 23 December 2020, 1:47 PM", "context": "\nTwo questions received from a student:1.     \r\nIn the revision slide, p22, about one producer multi consumer with\r\nunbounded buffer problem. Sorry for poor articulation of my question. My\r\nquestion is: I failed to find a way that fulfils two requirements using only\r\nsemaphores, which is: consumers concurrently access the buffer and take items,\r\nand consumers cannot enter the buffer when producer is inserting item into the\r\nbuffer, even though I use two semaphores, one for synchronization and the other\r\nfor mutual exclusion. Specifically:\r\nsuppose two semaphores, mutex (binary semaphore) and full (numeral semaphore), with initial value 1 and\r\n0 respectively.\r\nproducer does the following (similar code snippet is provided both in Modern\r\nOperating Systems and Operating Systems Concepts when talking about\r\nproducer-consumer problem):int item;\r\nwhile (true) {\r\n  item = produce_item();\r\n  sem_wait(&mutex);\r\n  /*critical section*/\r\n  insert_item(item); /*updating the buffer*/\r\n  sem_post(&mutex);\r\n  sem_post(&full); /*synchronisation*/\r\n}and consumer does the\r\nfollowing:int item;\r\nwhile (true) {\r\n  sem_wait(&full); /*wait if no item in the buffer*/\r\n  sem_wait(&mutex); /*wait if producer is updating the buffer*/\r\n  item = remove_item();\r\n  sem_post(&mutex);\r\n  consume_item(item);\r\n}The problem is that\r\nconsumers cannot concurrently enter the buffer, because of the binary semaphore\r\nmutex. Only one consumer can perform remove_item() at a time. Therefore I think using two\r\nsemaphores still cannot fulfil the two requirements.\r\nI read somewhere that condition variables may be used for such situation, but\r\nsince it is not introduced I guess it is unnecessary to use it here.\n2.     \r\nIn Lecture 20 and 21, about deciding whether it is a safe state, there\r\nare many glossaries with different names. Therefore I would like to check that\r\nthe following means the same thing:\r\nAssigned matrix = current allocation matrix (C matrix)\r\nrequest matrix = needed matrix (R matrix)\r\nclaim matrix = maximum matrix\nThank\r\nyou very much for your patience in answering my questions!\n"}, {"subject": "Two questions ", "time": "Wednesday, 23 December 2020, 1:47 PM", "context": "\nTwo questions received from a student:1.     \r\nIn the revision slide, p22, about one producer multi consumer with\r\nunbounded buffer problem. Sorry for poor articulation of my question. My\r\nquestion is: I failed to find a way that fulfils two requirements using only\r\nsemaphores, which is: consumers concurrently access the buffer and take items,\r\nand consumers cannot enter the buffer when producer is inserting item into the\r\nbuffer, even though I use two semaphores, one for synchronization and the other\r\nfor mutual exclusion. Specifically:\r\nsuppose two semaphores, mutex (binary semaphore) and full (numeral semaphore), with initial value 1 and\r\n0 respectively.\r\nproducer does the following (similar code snippet is provided both in Modern\r\nOperating Systems and Operating Systems Concepts when talking about\r\nproducer-consumer problem):int item;\r\nwhile (true) {\r\n  item = produce_item();\r\n  sem_wait(&mutex);\r\n  /*critical section*/\r\n  insert_item(item); /*updating the buffer*/\r\n  sem_post(&mutex);\r\n  sem_post(&full); /*synchronisation*/\r\n}and consumer does the\r\nfollowing:int item;\r\nwhile (true) {\r\n  sem_wait(&full); /*wait if no item in the buffer*/\r\n  sem_wait(&mutex); /*wait if producer is updating the buffer*/\r\n  item = remove_item();\r\n  sem_post(&mutex);\r\n  consume_item(item);\r\n}The problem is that\r\nconsumers cannot concurrently enter the buffer, because of the binary semaphore\r\nmutex. Only one consumer can perform remove_item() at a time. Therefore I think using two\r\nsemaphores still cannot fulfil the two requirements.\r\nI read somewhere that condition variables may be used for such situation, but\r\nsince it is not introduced I guess it is unnecessary to use it here.\n2.     \r\nIn Lecture 20 and 21, about deciding whether it is a safe state, there\r\nare many glossaries with different names. Therefore I would like to check that\r\nthe following means the same thing:\r\nAssigned matrix = current allocation matrix (C matrix)\r\nrequest matrix = needed matrix (R matrix)\r\nclaim matrix = maximum matrix\nThank\r\nyou very much for your patience in answering my questions!\n"}, {"subject": "Questions about paging", "time": "Tuesday, 22 December 2020, 4:09 PM", "context": "\nAs far as I know, paging uses fixed partitioning as well. So why did paging reduce internal fragmentation conpared to contiguous allocation? \n"}, {"subject": "Questions about paging", "time": "Tuesday, 22 December 2020, 4:09 PM", "context": "\nAs far as I know, paging uses fixed partitioning as well. So why did paging reduce internal fragmentation conpared to contiguous allocation? \n"}, {"subject": "semaphore example", "time": "Tuesday, 22 December 2020, 2:12 PM", "context": "\nA question received from a student:Dear Dr\r\nSaeid, \n \nI could not\r\nsee this slide clearly on the recording, and I cannot find it on the slides\r\ndownloaded from Moodle. \n \nPlease\r\ncould you share with me the slide, much appreciated!\n \nWith best\r\nregards, \n"}, {"subject": "semaphore example", "time": "Tuesday, 22 December 2020, 2:12 PM", "context": "\nA question received from a student:Dear Dr\r\nSaeid, \n \nI could not\r\nsee this slide clearly on the recording, and I cannot find it on the slides\r\ndownloaded from Moodle. \n \nPlease\r\ncould you share with me the slide, much appreciated!\n \nWith best\r\nregards, \n"}, {"subject": "Questions on Exception and Interrupt", "time": "Tuesday, 22 December 2020, 12:33 AM", "context": "\nHi Professors.There are several places that the lecture explains the “Exception” or “Interrupt”, but i found them not quite exact the same as the definition and explanation on textbook “Computer System: A Programer’s Perspective”, i hope a further clarification from the professors might be helpful.In Lecture 1Why the “Error Codes” can be seen as a Interrupt rather than Exception, and it seems that Interrupt is a kind of Exception, but the slides just mess them up.And for comparison to Java Exception, i think it’s better to distinguish between the HW Exception and SW Exception, as the following described in the book (p750) mentioned aboveThe textbook distinguished between different types of HW Exceptions:However, in the Virtual Memory slides, it says a Page Fault results in an Interrupt, according to the textbook, it may generate a ‘Fault’. Interrupt and Fault has different ECF, one is to pause and continue at the next instruction, the other is to (might) re-run the current instructionIn this page fault situation, I believe that it should be a Fault because CPU should re-run the memory fetching instruction after the Page Fault (and Memory managing system has bring back the missing memory from hard disk).Hoping for your reply.\n"}, {"subject": "Questions on Exception and Interrupt", "time": "Tuesday, 22 December 2020, 12:33 AM", "context": "\nHi Professors.There are several places that the lecture explains the “Exception” or “Interrupt”, but i found them not quite exact the same as the definition and explanation on textbook “Computer System: A Programer’s Perspective”, i hope a further clarification from the professors might be helpful.In Lecture 1Why the “Error Codes” can be seen as a Interrupt rather than Exception, and it seems that Interrupt is a kind of Exception, but the slides just mess them up.And for comparison to Java Exception, i think it’s better to distinguish between the HW Exception and SW Exception, as the following described in the book (p750) mentioned aboveThe textbook distinguished between different types of HW Exceptions:However, in the Virtual Memory slides, it says a Page Fault results in an Interrupt, according to the textbook, it may generate a ‘Fault’. Interrupt and Fault has different ECF, one is to pause and continue at the next instruction, the other is to (might) re-run the current instructionIn this page fault situation, I believe that it should be a Fault because CPU should re-run the memory fetching instruction after the Page Fault (and Memory managing system has bring back the missing memory from hard disk).Hoping for your reply.\n"}, {"subject": "A question about SCAN and LOOK-SCAN", "time": "Sunday, 20 December 2020, 10:05 PM", "context": "\nHi, professor.In the lecture, the total travel distance is calculate as  “Lift algorithm, SCAN” (for 11 1 36 16 34 9 12): |11-12|+|12-16|+|16-34|+|34-36|+|36-9|+|9-1|=60. But the definition of SCAN algorithm is \"When the head reaches the other end, however, it immediately returns to the beginning of the disk without servicing any requests on the return trip\". So why it does not calculate the distance between 36 and 40?If the total distance calculated by SCAN algorithm is |11-12|+|12-16|+|16-34|+|34-36|+|36-9|+|9-1|=60, how the distance is calculated by LOOK-SCAN algorithm?\n"}, {"subject": "A question about SCAN and LOOK-SCAN", "time": "Sunday, 20 December 2020, 10:05 PM", "context": "\nHi, professor.In the lecture, the total travel distance is calculate as  “Lift algorithm, SCAN” (for 11 1 36 16 34 9 12): |11-12|+|12-16|+|16-34|+|34-36|+|36-9|+|9-1|=60. But the definition of SCAN algorithm is \"When the head reaches the other end, however, it immediately returns to the beginning of the disk without servicing any requests on the return trip\". So why it does not calculate the distance between 36 and 40?If the total distance calculated by SCAN algorithm is |11-12|+|12-16|+|16-34|+|34-36|+|36-9|+|9-1|=60, how the distance is calculated by LOOK-SCAN algorithm?\n"}, {"subject": "OSC", "time": "Sunday, 20 December 2020, 9:15 PM", "context": "\nFor the shortest job first algorithm, if a process comes after the current process has excepted for a while, do we use the remaining time of the current process to compare with the coming process? Or use the burst time?\n"}, {"subject": "OSC", "time": "Sunday, 20 December 2020, 9:15 PM", "context": "\nFor the shortest job first algorithm, if a process comes after the current process has excepted for a while, do we use the remaining time of the current process to compare with the coming process? Or use the burst time?\n"}, {"subject": "OSC lecture2", "time": "Friday, 18 December 2020, 3:42 PM", "context": "\nAfter I fork and run the code, I found that the address of the variable iVar is the same and both variables of the two processes added to 10 which confused me(both processes access the same address the same time why not add to 20?). Does this relates to virtual memory? Could u plz express this question and explain?\n"}, {"subject": "OSC lecture2", "time": "Friday, 18 December 2020, 3:42 PM", "context": "\nAfter I fork and run the code, I found that the address of the variable iVar is the same and both variables of the two processes added to 10 which confused me(both processes access the same address the same time why not add to 20?). Does this relates to virtual memory? Could u plz express this question and explain?\n"}, {"subject": "About 2a", "time": "Sunday, 13 December 2020, 5:39 PM", "context": "\nDear Dr Saeid,As for \"The producers generate process and adds them to the end of the\r\nbounded buffer.\", but for SJF in 2a, jobs are supposed to be added into the buffer in order. In this case, can I not \"adds them to the end of the bounded buffer\", instead, add them using an inserting method to make it in the right position directly?Thank you!!!!!\n"}, {"subject": "About 2a", "time": "Sunday, 13 December 2020, 5:39 PM", "context": "\nDear Dr Saeid,As for \"The producers generate process and adds them to the end of the\r\nbounded buffer.\", but for SJF in 2a, jobs are supposed to be added into the buffer in order. In this case, can I not \"adds them to the end of the bounded buffer\", instead, add them using an inserting method to make it in the right position directly?Thank you!!!!!\n"}, {"subject": " Semaphores/Mutexes", "time": "Sunday, 13 December 2020, 4:27 PM", "context": "\nHi Dr. Saeid,Is it acceptable if I implement task2 only by mutexes without semaphores?Thank you!\n"}, {"subject": " Semaphores/Mutexes", "time": "Sunday, 13 December 2020, 4:27 PM", "context": "\nHi Dr. Saeid,Is it acceptable if I implement task2 only by mutexes without semaphores?Thank you!\n"}, {"subject": "MAX_NUMBER_OF_JOBS", "time": "Sunday, 13 December 2020, 3:55 PM", "context": "\nDear Dr Saeid,It is mentioned in the CW specification that generate output similar in format to the example provided on Moodle for this requirement (for 100 jobs, using a buffer size of 10). But, I think it uses a buffer size of 5 in the sample output. So, which is correct?Thank you.\n"}, {"subject": "MAX_NUMBER_OF_JOBS", "time": "Sunday, 13 December 2020, 3:55 PM", "context": "\nDear Dr Saeid,It is mentioned in the CW specification that generate output similar in format to the example provided on Moodle for this requirement (for 100 jobs, using a buffer size of 10). But, I think it uses a buffer size of 5 in the sample output. So, which is correct?Thank you.\n"}, {"subject": "Smallest Critical Section for Task 2", "time": "Sunday, 13 December 2020, 8:21 AM", "context": "\nHello Dr Saeid and Dr Qian,I want to ask regarding the smallest critical section for Task 2.In the Coursework sheet, it is mentioned: Synchronise all critical sections in a correct and efficient manner, and only when strictly necessary keeping the critical sections to the smallest possible code set(s). And we are also expected to get output similar to the sample output given on Moodle.I realize that the Critical Section could be small, efficient, and it behaves as expectation, however,  to get similar output as given, the Critical Section might need to be bigger. So, which one should be our priority, do we keep the CS as small as possible, or get similar output?Thank you.\n"}, {"subject": "Smallest Critical Section for Task 2", "time": "Sunday, 13 December 2020, 8:21 AM", "context": "\nHello Dr Saeid and Dr Qian,I want to ask regarding the smallest critical section for Task 2.In the Coursework sheet, it is mentioned: Synchronise all critical sections in a correct and efficient manner, and only when strictly necessary keeping the critical sections to the smallest possible code set(s). And we are also expected to get output similar to the sample output given on Moodle.I realize that the Critical Section could be small, efficient, and it behaves as expectation, however,  to get similar output as given, the Critical Section might need to be bigger. So, which one should be our priority, do we keep the CS as small as possible, or get similar output?Thank you.\n"}, {"subject": "About testing the program", "time": "Sunday, 13 December 2020, 2:15 AM", "context": "\nDear Dr Saeid,Whether our program will be tested with different macro values defined in `coursework.h` like MAX_NUMBER_OF_JOBS, NUMBER_OF_PRODUCERS, etc.Should we handle the exceptions caused by unexpected input macro values?Thank you.\n"}, {"subject": "About testing the program", "time": "Sunday, 13 December 2020, 2:15 AM", "context": "\nDear Dr Saeid,Whether our program will be tested with different macro values defined in `coursework.h` like MAX_NUMBER_OF_JOBS, NUMBER_OF_PRODUCERS, etc.Should we handle the exceptions caused by unexpected input macro values?Thank you.\n"}, {"subject": "About Q1 a", "time": "Saturday, 12 December 2020, 9:53 PM", "context": "\nDear Dr Saeid,it is said that \"Whether jobs are added at the end of the linked list in an efficient manner, that is by using the tail of the linked list rather than traversing the entire linked list first.\"I think the above sentence means we need to utilise tail and addLast() to add process at the end of the queue, am I right?HOWEVER,Does it matter to *insert generated processes into the ready queue directly by traversing to find a suitable place(a self-defined function)* rather than *generate all and sort them first then add them by addLast() into the ready queue*?And, for \"In both cases, your implementation should contain a function that generates a pre-defined NUMBER_OF_PROCESSES \", Does the function here means a real function that has a function name and signature or just a feature?\n"}, {"subject": "About Q1 a", "time": "Saturday, 12 December 2020, 9:53 PM", "context": "\nDear Dr Saeid,it is said that \"Whether jobs are added at the end of the linked list in an efficient manner, that is by using the tail of the linked list rather than traversing the entire linked list first.\"I think the above sentence means we need to utilise tail and addLast() to add process at the end of the queue, am I right?HOWEVER,Does it matter to *insert generated processes into the ready queue directly by traversing to find a suitable place(a self-defined function)* rather than *generate all and sort them first then add them by addLast() into the ready queue*?And, for \"In both cases, your implementation should contain a function that generates a pre-defined NUMBER_OF_PROCESSES \", Does the function here means a real function that has a function name and signature or just a feature?\n"}, {"subject": "question of response andturnaround time in task1b", "time": "Saturday, 12 December 2020, 9:20 PM", "context": "\n                            Dear Dr Saeid,\r\nis it matter if I have a slightly difference in response time and turnaround time \r\n\r\nfor examplefor   turnaround time =975(in your output)  i got 976(for my output)\n"}, {"subject": "question of response andturnaround time in task1b", "time": "Saturday, 12 December 2020, 9:20 PM", "context": "\n                            Dear Dr Saeid,\r\nis it matter if I have a slightly difference in response time and turnaround time \r\n\r\nfor examplefor   turnaround time =975(in your output)  i got 976(for my output)\n"}, {"subject": "Random Segmentation Fault", "time": "Saturday, 12 December 2020, 8:13 PM", "context": "\n                            Dear Dr Saeid,My executable file seems to randomly have the Segmentation Fault now. It may work sometimes, but it may also not work. I don't know if it is my coding problem or because RAM of cslinux is full.\n"}, {"subject": "Random Segmentation Fault", "time": "Saturday, 12 December 2020, 8:13 PM", "context": "\n                            Dear Dr Saeid,My executable file seems to randomly have the Segmentation Fault now. It may work sometimes, but it may also not work. I don't know if it is my coding problem or because RAM of cslinux is full.\n"}, {"subject": "question about TASK1b", "time": "Saturday, 12 December 2020, 4:28 PM", "context": "\nDear professor,As the cw given ‘Note that you are expected to use multiple linked lists for the PQ algorithm, one for each priority level ‘ Do we need to create 32 linked list or can we use one linked list for one priority that actually exist or both is ok?Looking forward to your reply.\n                        "}, {"subject": "question about TASK1b", "time": "Saturday, 12 December 2020, 4:28 PM", "context": "\nDear professor,As the cw given ‘Note that you are expected to use multiple linked lists for the PQ algorithm, one for each priority level ‘ Do we need to create 32 linked list or can we use one linked list for one priority that actually exist or both is ok?Looking forward to your reply.\n                        "}, {"subject": "question about TASK2a", "time": "Friday, 11 December 2020, 1:31 PM", "context": "\nHi, professor,The sample output:Producer = 0, Items Produced = 1, New Process Id = 0, Burst Time = 134Producer = 0, Items Produced = 2, New Process Id = 1, Burst Time = 28Producer = 0, Items Produced = 3, New Process Id = 2, Burst Time = 144Producer = 0, Items Produced = 4, New Process Id = 3, Burst Time = 137Producer = 0, Items Produced = 5, New Process Id = 4, Burst Time = 100Consumer = 0, Process Id = 1, Previous Burst Time = 28, New Burst Time = 0, Response Time = 0, Turnaround Time = 28----------------------------------------------------------------------------------------------------------------------------------------------------But  if my output is :Producer = 0, Items Produced = 1, New Process Id = 0, Burst Time = 134Producer = 0, Items Produced = 2, New Process Id = 1, Burst Time = 28Producer = 0, Items Produced = 3, New Process Id = 2, Burst Time = 144Producer = 0, Items Produced = 4, New Process Id = 3, Burst Time = 137Producer = 1, Items Produced = 5, New Process Id = 4, Burst Time = 100Consumer = 2, Process Id = 1, Previous Burst Time = 28, New Burst Time = 0, Response Time = 1, Turnaround Time = 29-----------------------------------------------------------------------------------------------------------------------------------------------------Is the situation mentioned above acceptable or will cause losing marks?\n"}, {"subject": "question about TASK2a", "time": "Friday, 11 December 2020, 1:31 PM", "context": "\nHi, professor,The sample output:Producer = 0, Items Produced = 1, New Process Id = 0, Burst Time = 134Producer = 0, Items Produced = 2, New Process Id = 1, Burst Time = 28Producer = 0, Items Produced = 3, New Process Id = 2, Burst Time = 144Producer = 0, Items Produced = 4, New Process Id = 3, Burst Time = 137Producer = 0, Items Produced = 5, New Process Id = 4, Burst Time = 100Consumer = 0, Process Id = 1, Previous Burst Time = 28, New Burst Time = 0, Response Time = 0, Turnaround Time = 28----------------------------------------------------------------------------------------------------------------------------------------------------But  if my output is :Producer = 0, Items Produced = 1, New Process Id = 0, Burst Time = 134Producer = 0, Items Produced = 2, New Process Id = 1, Burst Time = 28Producer = 0, Items Produced = 3, New Process Id = 2, Burst Time = 144Producer = 0, Items Produced = 4, New Process Id = 3, Burst Time = 137Producer = 1, Items Produced = 5, New Process Id = 4, Burst Time = 100Consumer = 2, Process Id = 1, Previous Burst Time = 28, New Burst Time = 0, Response Time = 1, Turnaround Time = 29-----------------------------------------------------------------------------------------------------------------------------------------------------Is the situation mentioned above acceptable or will cause losing marks?\n"}, {"subject": "Question about code format", "time": "Friday, 11 December 2020, 1:00 PM", "context": "\nHi professor, Is the format of the code is a marking criteria? Is it necessary to divide the code into multiple functions？\n"}, {"subject": "Question about code format", "time": "Friday, 11 December 2020, 1:00 PM", "context": "\nHi professor, Is the format of the code is a marking criteria? Is it necessary to divide the code into multiple functions？\n"}, {"subject": "Questions about coursework submission", "time": "Friday, 11 December 2020, 11:20 AM", "context": "\n                            In the \"submission requirements\" section,\"The source files must be named TASKX.c, any output files should be named\r\nTASKX.txt, with X being the number of the task.\"I'm wondering if we also need to submit the output files of each task. \n"}, {"subject": "Questions about coursework submission", "time": "Friday, 11 December 2020, 11:20 AM", "context": "\n                            In the \"submission requirements\" section,\"The source files must be named TASKX.c, any output files should be named\r\nTASKX.txt, with X being the number of the task.\"I'm wondering if we also need to submit the output files of each task. \n"}, {"subject": "int-pointer-cast warning", "time": "Thursday, 10 December 2020, 7:32 PM", "context": "\nHi professor, I tried to run the sample code in the ppt of Lec06. And then I found the trouble: It works fine, but has the warning. And I found that the fourth argument can only be a pointer. So, how can I pass a normal integer to \"hello_world\"?Looking forward to your apply.\n"}, {"subject": "int-pointer-cast warning", "time": "Thursday, 10 December 2020, 7:32 PM", "context": "\nHi professor, I tried to run the sample code in the ppt of Lec06. And then I found the trouble: It works fine, but has the warning. And I found that the fourth argument can only be a pointer. So, how can I pass a normal integer to \"hello_world\"?Looking forward to your apply.\n"}, {"subject": "Some questions about CW TASK2", "time": "Thursday, 10 December 2020, 3:14 PM", "context": "\nDear professor,1. In the TASK2 specification,  it says that \" The consumers will remove process from the start of the list and simulate them “running” on the CPU \" and in the \"final version include\" part, it states that \"A consumer function that removes elements from the end of the buffer (one at a time).\"  So which side does the consumer need to remove element?2. In the TASK2 \"final version include\" part, it says \"The maximum size of this list should be configured to not exceed, e.g., 50 elements.\" in the first point and  \"(for 100 jobs, using a buffer size of 10). \" in the final point, but the buffer size defined in the code is 5. So we should do TASK2 with which buffer size?\n"}, {"subject": "Some questions about CW TASK2", "time": "Thursday, 10 December 2020, 3:14 PM", "context": "\nDear professor,1. In the TASK2 specification,  it says that \" The consumers will remove process from the start of the list and simulate them “running” on the CPU \" and in the \"final version include\" part, it states that \"A consumer function that removes elements from the end of the buffer (one at a time).\"  So which side does the consumer need to remove element?2. In the TASK2 \"final version include\" part, it says \"The maximum size of this list should be configured to not exceed, e.g., 50 elements.\" in the first point and  \"(for 100 jobs, using a buffer size of 10). \" in the final point, but the buffer size defined in the code is 5. So we should do TASK2 with which buffer size?\n"}, {"subject": "RR time interval. ", "time": "Thursday, 10 December 2020, 11:37 AM", "context": "\nDear allThis is the answer for a question regarding RR time slice:According to the source code, #define TIME_SLICE 5, is RR time slice which this algorithm use for scheduling. You need this for RR algorithm setup and execution.*** You do not need to use #define BOOST_INTERVAL 20 for this coursework. This should be used to boost the priority queues under specific conditions. So, please avoid using it for this coursework. Hope this helps\n"}, {"subject": "RR time interval. ", "time": "Thursday, 10 December 2020, 11:37 AM", "context": "\nDear allThis is the answer for a question regarding RR time slice:According to the source code, #define TIME_SLICE 5, is RR time slice which this algorithm use for scheduling. You need this for RR algorithm setup and execution.*** You do not need to use #define BOOST_INTERVAL 20 for this coursework. This should be used to boost the priority queues under specific conditions. So, please avoid using it for this coursework. Hope this helps\n"}, {"subject": "Question about CW Task2", "time": "Tuesday, 8 December 2020, 9:05 PM", "context": "\nDear professor,I do not quite understand the requirement \"In the case of the PQs, the maximum number of elements across all queues (every priority level is represented by a separate linked list) should not exceed MAX_BUFFER_SIZE.\". Understanding 1. From my understanding, across all queues means if we have 4 levels, the summation of the 4 levels element should not exceed MAX_BUFFER_SIZE.Understanding 2. Or some could understand it as for each queue, the maximum number of element should not exceed MAX_BUFFER_SIZE. Is my understanding 1.  correct?\n"}, {"subject": "Question about CW Task2", "time": "Tuesday, 8 December 2020, 9:05 PM", "context": "\nDear professor,I do not quite understand the requirement \"In the case of the PQs, the maximum number of elements across all queues (every priority level is represented by a separate linked list) should not exceed MAX_BUFFER_SIZE.\". Understanding 1. From my understanding, across all queues means if we have 4 levels, the summation of the 4 levels element should not exceed MAX_BUFFER_SIZE.Understanding 2. Or some could understand it as for each queue, the maximum number of element should not exceed MAX_BUFFER_SIZE. Is my understanding 1.  correct?\n"}, {"subject": "Question about getting output after compiling", "time": "Friday, 4 December 2020, 2:14 PM", "context": "\nA question received from a students as below:\nI\r\nhave problem when I tried to get the output of my code and it is shown as the\r\nfollowing picture. I successfully compiled and it can't get the output when I\r\nuse ./TASK1b or ./TASK1b coursework linkedlist. So what should I do to deal\r\nwith problem?\n\n"}, {"subject": "Question about getting output after compiling", "time": "Friday, 4 December 2020, 2:14 PM", "context": "\nA question received from a students as below:\nI\r\nhave problem when I tried to get the output of my code and it is shown as the\r\nfollowing picture. I successfully compiled and it can't get the output when I\r\nuse ./TASK1b or ./TASK1b coursework linkedlist. So what should I do to deal\r\nwith problem?\n\n"}, {"subject": "A little question about coursework output", "time": "Saturday, 21 November 2020, 12:22 PM", "context": "\nHi, I noticed that the sample output has been uploaded to the moodle.I guess in Task1a.txt, the value of \"Priority\" is incorrect because in the description of the coursework the maximum value of priority should not exceed MAX_PRIORITY, perhaps the previous burst time has been mistakenly set to priority?By the way, do I need to make sure the output format and output value are exactly the same as the sample output? Or a slight difference between my output and the sample output value is allowed?Looking forward to your reply :D\n"}, {"subject": "A little question about coursework output", "time": "Saturday, 21 November 2020, 12:22 PM", "context": "\nHi, I noticed that the sample output has been uploaded to the moodle.I guess in Task1a.txt, the value of \"Priority\" is incorrect because in the description of the coursework the maximum value of priority should not exceed MAX_PRIORITY, perhaps the previous burst time has been mistakenly set to priority?By the way, do I need to make sure the output format and output value are exactly the same as the sample output? Or a slight difference between my output and the sample output value is allowed?Looking forward to your reply :D\n"}, {"subject": "Questions about this coursework", "time": "Friday, 20 November 2020, 5:18 PM", "context": "\n1. I did not find sample output of this coursework in moodle.2. In the given code, There is a statement.     > \"#define BOOST_INTERVAL 20\"     which is hard to understand its meaning. Could you please explain it for me.\n"}, {"subject": "Questions about this coursework", "time": "Friday, 20 November 2020, 5:18 PM", "context": "\n1. I did not find sample output of this coursework in moodle.2. In the given code, There is a statement.     > \"#define BOOST_INTERVAL 20\"     which is hard to understand its meaning. Could you please explain it for me.\n"}, {"subject": "Questions about coursework task 1", "time": "Tuesday, 17 November 2020, 10:54 AM", "context": "\n\"In both cases, your implementation\r\nshould contain a function that generates a pre-defined NUMBER_OF_PROCESSES (this\r\nconstant is defined in coursework.h) and stores them in a linked list (using a SJF approach\r\nin both cases).\" Hence, the function mentioned above should generate a pre-defined number of processes, and then store them into the ready queue based on the SJF approach. In other words, these processes should be stored in order of ascending processing time in the ready queue for both TASK1a and TASK1b.\"Note that the priority queue algorithm uses a Round Robin\r\nwithin the priority levels.\" \"In the linked list ready queue implementation, the process will be added to the end and removed from the front.\"In TASK1a, we have only one ready queue and the processes will be removed from the front of the ready queue since we are using the SJF approach and the processes residing in the ready queue is also stored in order of ascending processing time. No processes will have the chance to go back to the ready queue because once a process is removed from the front of the ready queue, it will monopolize the \"CPU\" until it completes execution. In TASK1b, we may have several ready queues with different priorities. The processes with lower priorities will not be executed until all the processes with higher priorities get executed. For the processes within the same priority, we'll use the RR approach, which means once the time quantum is passed, the current process executing in the \"CPU\" will be added to the end of the ready queue, and the process in the front of the ready queue will be removed from the ready queue and get executed.I want to make sure that my understanding is correct.\n"}, {"subject": "Questions about coursework task 1", "time": "Tuesday, 17 November 2020, 10:54 AM", "context": "\n\"In both cases, your implementation\r\nshould contain a function that generates a pre-defined NUMBER_OF_PROCESSES (this\r\nconstant is defined in coursework.h) and stores them in a linked list (using a SJF approach\r\nin both cases).\" Hence, the function mentioned above should generate a pre-defined number of processes, and then store them into the ready queue based on the SJF approach. In other words, these processes should be stored in order of ascending processing time in the ready queue for both TASK1a and TASK1b.\"Note that the priority queue algorithm uses a Round Robin\r\nwithin the priority levels.\" \"In the linked list ready queue implementation, the process will be added to the end and removed from the front.\"In TASK1a, we have only one ready queue and the processes will be removed from the front of the ready queue since we are using the SJF approach and the processes residing in the ready queue is also stored in order of ascending processing time. No processes will have the chance to go back to the ready queue because once a process is removed from the front of the ready queue, it will monopolize the \"CPU\" until it completes execution. In TASK1b, we may have several ready queues with different priorities. The processes with lower priorities will not be executed until all the processes with higher priorities get executed. For the processes within the same priority, we'll use the RR approach, which means once the time quantum is passed, the current process executing in the \"CPU\" will be added to the end of the ready queue, and the process in the front of the ready queue will be removed from the ready queue and get executed.I want to make sure that my understanding is correct.\n"}, {"subject": "Coursework description", "time": "Sunday, 15 November 2020, 8:07 PM", "context": "\n\"In both cases, your implementation\r\nshould contain a function that generates a pre-defined NUMBER_OF_PROCESSES (this\r\nconstant is defined in coursework.h) and stores them in a linked list (using a SJF approach\r\nin both cases).\"I have some doubts about the last two words \"both cases\".  First of all, using the SJF approach in SJF is easily understandable, but how to use the SJF in PQ? Do you mean that if we face the situation that several processes have the same priority,  we apply SJF among them to decide their position of the linked list when we implement it at the beginning?\n"}, {"subject": "Coursework description", "time": "Sunday, 15 November 2020, 8:07 PM", "context": "\n\"In both cases, your implementation\r\nshould contain a function that generates a pre-defined NUMBER_OF_PROCESSES (this\r\nconstant is defined in coursework.h) and stores them in a linked list (using a SJF approach\r\nin both cases).\"I have some doubts about the last two words \"both cases\".  First of all, using the SJF approach in SJF is easily understandable, but how to use the SJF in PQ? Do you mean that if we face the situation that several processes have the same priority,  we apply SJF among them to decide their position of the linked list when we implement it at the beginning?\n"}, {"subject": "Question of a simple program about progress & thread", "time": "Friday, 16 October 2020, 11:14 PM", "context": "\n                            Hi, every one,I have been met with some confusion when I was solving one exercise (see below) in book Operating System ConceptsI have worked out the answer as 4 and 2. But the correct answer is 6 and 2. Is there anyone interested in this question and help explain a little bit? :)\n"}, {"subject": "Question of a simple program about progress & thread", "time": "Friday, 16 October 2020, 11:14 PM", "context": "\n                            Hi, every one,I have been met with some confusion when I was solving one exercise (see below) in book Operating System ConceptsI have worked out the answer as 4 and 2. But the correct answer is 6 and 2. Is there anyone interested in this question and help explain a little bit? :)\n"}, {"subject": "Two questions about Concurrency", "time": "Tuesday, 13 October 2020, 8:44 PM", "context": "\n                            Hi everyone, I have two questions regarding process concurrency:1. When we talk about Peterson's solution, can there be any interruptions occurring when codes of a process's critical section is being executed if there are no hardware supporting on it? That is, whether code in the critical section is marked to be uninterrupted (may be marked by compiler and idetified by CPU?) or we just assume there can be no interruption in the critical section (and in fact it is possible to be interrupted?).2. How can we prove that hardware supported lock does not meet bounded waiting criteria (i.e. can be always busy waiting) compared with Peterson's solution? Is there any possibility that we use coding to address this problem?\n"}, {"subject": "Two questions about Concurrency", "time": "Tuesday, 13 October 2020, 8:44 PM", "context": "\n                            Hi everyone, I have two questions regarding process concurrency:1. When we talk about Peterson's solution, can there be any interruptions occurring when codes of a process's critical section is being executed if there are no hardware supporting on it? That is, whether code in the critical section is marked to be uninterrupted (may be marked by compiler and idetified by CPU?) or we just assume there can be no interruption in the critical section (and in fact it is possible to be interrupted?).2. How can we prove that hardware supported lock does not meet bounded waiting criteria (i.e. can be always busy waiting) compared with Peterson's solution? Is there any possibility that we use coding to address this problem?\n"}, {"subject": "OSC", "time": "Tuesday, 13 October 2020, 11:06 AM", "context": "\nI wanna know does different processors can have one critical section for themselves?\n"}, {"subject": "OSC", "time": "Tuesday, 13 October 2020, 11:06 AM", "context": "\nI wanna know does different processors can have one critical section for themselves?\n"}, {"subject": "Two questions about Process Scheduling", "time": "Friday, 9 October 2020, 9:47 PM", "context": "\nDear all,As I read through related chapters of the book Operating System Concepts about process scheduling, I found two differences with the content in the lecture slide:1) When evaluating scheduling algorithms, the book uses \"waiting time\" instead of \"response time\" which is used in the lecture slide. The book also clearly explain the two concepts:From my understanding, since in one process there might be some I/O bursts, the defined response time should also include the I/O time which makes the process in the \"blocked state\" rather than \"ready state\". That it to say, Response Time = Waiting Time + I/O time (Just from my understanding and I don't know whether it's correct or not). If this is correct, I think \"waiting time\" would be better than \"response time\", because just as the difinition of \"waiting time\" says -- The CPU-scheduling algorithm does not affect the amount of time during which a process executes or does I/O. It affects only the amount of time that a process spends waiting in the ready queue. And using \"response time\" may simply neglect the time spent on I/O.2) For the SJF algorithm, the book clearly writes that it can be either preemptive or non-preemptive, which contradicts the lecture slides \"A non preemptive algorithm that starts processes in order of ascending processing time using a provided/known estimate of the processing\". I hope there are some clarification about this.Hope I have made clear about my confusions :)\n"}, {"subject": "Two questions about Process Scheduling", "time": "Friday, 9 October 2020, 9:47 PM", "context": "\nDear all,As I read through related chapters of the book Operating System Concepts about process scheduling, I found two differences with the content in the lecture slide:1) When evaluating scheduling algorithms, the book uses \"waiting time\" instead of \"response time\" which is used in the lecture slide. The book also clearly explain the two concepts:From my understanding, since in one process there might be some I/O bursts, the defined response time should also include the I/O time which makes the process in the \"blocked state\" rather than \"ready state\". That it to say, Response Time = Waiting Time + I/O time (Just from my understanding and I don't know whether it's correct or not). If this is correct, I think \"waiting time\" would be better than \"response time\", because just as the difinition of \"waiting time\" says -- The CPU-scheduling algorithm does not affect the amount of time during which a process executes or does I/O. It affects only the amount of time that a process spends waiting in the ready queue. And using \"response time\" may simply neglect the time spent on I/O.2) For the SJF algorithm, the book clearly writes that it can be either preemptive or non-preemptive, which contradicts the lecture slides \"A non preemptive algorithm that starts processes in order of ascending processing time using a provided/known estimate of the processing\". I hope there are some clarification about this.Hope I have made clear about my confusions :)\n"}, {"subject": "A question about user thread", "time": "Tuesday, 6 October 2020, 10:29 PM", "context": "\nWhen I was reading textbook, I found the description below very confusing:> Another, and really the most devastating, argument against user-level threads is that programmers generally want threads precisely in applications where the threads block often, as, for example, in a multithreaded Web server. These threads are constantly making system calls. Once a trap has occurred to the kernel to carry out the system call, it is hardly any more work for the kernel to switch threads if the old one has blocked, and having the kernel do this eliminates the need for constantly making select system calls that check to see if read system calls are safe. For applications that are essentially entirely CPU bound and rarely block, what is the point of having threads at all? No one would seriously propose computing the first n prime numbers or playing chess using threads because there is nothing to be gained by doing it that way.I don't understand what this description means. Can anybody explain it for me?\n"}, {"subject": "A question about user thread", "time": "Tuesday, 6 October 2020, 10:29 PM", "context": "\nWhen I was reading textbook, I found the description below very confusing:> Another, and really the most devastating, argument against user-level threads is that programmers generally want threads precisely in applications where the threads block often, as, for example, in a multithreaded Web server. These threads are constantly making system calls. Once a trap has occurred to the kernel to carry out the system call, it is hardly any more work for the kernel to switch threads if the old one has blocked, and having the kernel do this eliminates the need for constantly making select system calls that check to see if read system calls are safe. For applications that are essentially entirely CPU bound and rarely block, what is the point of having threads at all? No one would seriously propose computing the first n prime numbers or playing chess using threads because there is nothing to be gained by doing it that way.I don't understand what this description means. Can anybody explain it for me?\n"}, {"subject": "An example for RR scheduling, \"performance evaluation\"", "time": "Tuesday, 6 October 2020, 6:18 PM", "context": "\nDear allAs some of you asked for an example to see (and understand) the performance of Round Robin scheduling algorithm (e.g. response time, turnaround time and system throughput) when the length of quantum (time slices) changes, I have prepared a visual one here.Please have a look and see the performance of RR if either long or short time slices are used. You are welcome to attend the Q/A meetings during my office hours if you still have more questions. hope this helpsthanks Saeid\n"}, {"subject": "An example for RR scheduling, \"performance evaluation\"", "time": "Tuesday, 6 October 2020, 6:18 PM", "context": "\nDear allAs some of you asked for an example to see (and understand) the performance of Round Robin scheduling algorithm (e.g. response time, turnaround time and system throughput) when the length of quantum (time slices) changes, I have prepared a visual one here.Please have a look and see the performance of RR if either long or short time slices are used. You are welcome to attend the Q/A meetings during my office hours if you still have more questions. hope this helpsthanks Saeid\n"}, {"subject": "A student question: lec4-5", "time": "Monday, 5 October 2020, 8:56 PM", "context": "\nI am\r\nquite confused on the today’s slide that why reducing the response time\r\nmay worsen the throughput and increase the turn around time? It seems that they\r\nare negatively correlated, but in today’s quiz, they are positive correlated. I\r\nwonder if you can help me. Many thanks:)\n"}, {"subject": "A student question: lec4-5", "time": "Monday, 5 October 2020, 8:56 PM", "context": "\nI am\r\nquite confused on the today’s slide that why reducing the response time\r\nmay worsen the throughput and increase the turn around time? It seems that they\r\nare negatively correlated, but in today’s quiz, they are positive correlated. I\r\nwonder if you can help me. Many thanks:)\n"}, {"subject": "Question about \"The CPU can only access main memory directly\"", "time": "Tuesday, 22 September 2020, 2:31 PM", "context": "\nIt is said that \"The CPU can only access main memory directly\".1. Does it mean the CPU cannot access registers and cache directly?2. Are registers and cache parts of the CPU?3. In the last lecture, you said context switch is able to switch between user mode and kernel mode. However, it seems more likely that TRAP does this while CS does switch between processes. Does this mean context switch may conclude TRAP process? I'm a bit confused about this, could you help me with this?\n"}, {"subject": "Question about \"The CPU can only access main memory directly\"", "time": "Tuesday, 22 September 2020, 2:31 PM", "context": "\nIt is said that \"The CPU can only access main memory directly\".1. Does it mean the CPU cannot access registers and cache directly?2. Are registers and cache parts of the CPU?3. In the last lecture, you said context switch is able to switch between user mode and kernel mode. However, it seems more likely that TRAP does this while CS does switch between processes. Does this mean context switch may conclude TRAP process? I'm a bit confused about this, could you help me with this?\n"}, {"subject": "Office hours. ", "time": "Tuesday, 22 December 2020, 9:53 AM", "context": "\nDear allPlease feel free to join our office hours if you have any question or need help. Please make sure you use the updated slides and materials, you can download them from the Moodle. ** For the students who are still away, the online Q/A sessions are available to help you if you have any question. Please visit click here to participate in SEM/SET survey if you have not made this yet. Thanks \n"}, {"subject": "Question answer", "time": "Sunday, 27 December 2020, 4:28 PM", "context": "\nI will be in my office Monday afternoon 2-4 pm, if you want ask questions related to memory management, please come to my office\n"}, {"subject": "Office hours. ", "time": "Tuesday, 22 December 2020, 9:53 AM", "context": "\nDear allPlease feel free to join our office hours if you have any question or need help. Please make sure you use the updated slides and materials, you can download them from the Moodle. ** For the students who are still away, the online Q/A sessions are available to help you if you have any question. Please visit click here to participate in SEM/SET survey if you have not made this yet. Thanks \n"}, {"subject": "Question answer", "time": "Sunday, 27 December 2020, 4:28 PM", "context": "\nI will be in my office Monday afternoon 2-4 pm, if you want ask questions related to memory management, please come to my office\n"}, {"subject": "Office hours. ", "time": "Tuesday, 22 December 2020, 9:53 AM", "context": "\nDear allPlease feel free to join our office hours if you have any question or need help. Please make sure you use the updated slides and materials, you can download them from the Moodle. ** For the students who are still away, the online Q/A sessions are available to help you if you have any question. Please visit click here to participate in SEM/SET survey if you have not made this yet. Thanks \n"}, {"subject": "SET/SEM Survey is Back.", "time": "Thursday, 17 December 2020, 4:44 PM", "context": "\nDear allSET/SEM survey is back now. This was a problem with Moodle, and seems this is sorted out now :) Please visit click here to participate in the survey if you have not made this yet. Thanks \n"}, {"subject": "Revision slides", "time": "Monday, 14 December 2020, 11:44 AM", "context": "\nDear allRevision slides are now available. This could help you to see how the exam looks like!Good luck with your CW. The name of your zip file should be your username (according to the CW description), please ignore the pervious announcement for the naming(s). **** to participate in SET/SEM survey, please visit click here. Thanks \n"}, {"subject": "Exam revision and CW drop-in, Monday 2020-12-14", "time": "Sunday, 13 December 2020, 12:53 PM", "context": "\nDear allDue to receive a number of questions for the CW, we will have a CW drop-in session tomorrow after the revision lecture. \n *****Please join this session and revision tomorrow\r\nif you have any question or need help. I believe the sessions tomorrow would be\r\nvery helpful for you all.\nSee you.\n"}, {"subject": "Revision week ", "time": "Friday, 11 December 2020, 4:48 PM", "context": "\nDear allWe highly encourage you all to attend Monday 2020/12/14 sessions, focusing on OSC exam and Coursework. This is a very important lecture, as we will talk about the exam and the coursework submissions and you will have a chance to figure out lots of details then.See you all\n"}, {"subject": "**VERY VERY IMPORTANT: OSC Coursework ", "time": "Tuesday, 8 December 2020, 11:43 AM", "context": "\nDear allThe coursework submission link is now open under coursework section on OSC Moodle page. {Please click here, to see the submission page.}***Note- To avoid misunderstanding, the coursework deadline is updated to 15th December 2020, 00:05 AM, local time. This is a HARD deadline, so, I highly recommend you to submit the coursework as soon as possible.Please make sure submit your coursework as a single zip file, named, \"XXXXXXYYY\" where XXXXX is your student number and YYY is your first name.**** to participate in SET/SEM survey, please visit click here. ThanksSaeid\n"}, {"subject": "** IMPORTANT: SET/SEM survey", "time": "Monday, 7 December 2020, 11:15 AM", "context": "\nDear allThis is the time for SET/SEM survey. This is very important that you all spend 5 minutes aiming to participate in this survey.The survey is available here:https://bluecastle-cn-surveys.nottingham.ac.ukor you can click here to see the QR codes. Thanks Saeid and Qian\n"}, {"subject": "Lab sample codes and exam past papers", "time": "Wednesday, 2 December 2020, 10:23 AM", "context": "\nDear allThe sample codes for some of the lab tasks are now available on Moodle. Please have a look to see how they work.The past exam papers are now available, we will talk about the exam further, next week, during the revision session.Hope this helps  \n"}, {"subject": "OSC labs: lab activities ", "time": "Thursday, 26 November 2020, 4:39 PM", "context": "\nDear allAs we finished the lab tasks this week and according to the module schedule, there is no more lab left for the next weeks. Instead of this, we have organised drop-in sessions for the next two weeks, on Wednesdays 9-11 AM. Please join if you have any questions about OSC coursework. Sample answers for task 7 and 8 are now available on the Moodle. Hope this helps\n"}, {"subject": "Slides with Quizzes ", "time": "Monday, 23 November 2020, 11:36 AM", "context": "\nDear allAccording to our discussion today in the class, I will update the slides and add the quizzes after each lecture.  Slides for lecture 21 and 22 with quizzes are now available on the Moodle. Hope this helpsSaeid\n"}, {"subject": "Coursework Task1/b", "time": "Monday, 23 November 2020, 11:32 AM", "context": "\nDear allFurther to a question, regarding the sample output for Task1b, we checked the coursework description and found something unclear. To make this clear, please have a look below:There are two parts in Task1, one with SJF scheduling and another PQ. Task1a should be clear as SJF will be in charge of process scheduling. Task1b focuses on PQ queues which work according to RR scheduling. The processes are enqueued according to their priorities (PQs) and then scheduled one by one using RR for each queue. Indeed, PQ scheduling is used for different priority queues, whereas round robin algorithm (***not SJF****) should be used by the processes with the same priorities in each queue.The coursework description is updated and uploaded accordingly. Hope this helps\n"}, {"subject": "Coursework sample outputs", "time": "Friday, 20 November 2020, 8:25 PM", "context": "\nDear allPlease visit the Moodle page to see sample outputs for the coursework.Hope this helps\n"}, {"subject": "Sample outputs for OSC labs: task 5 and 6", "time": "Wednesday, 18 November 2020, 3:08 PM", "context": "\nDear allSample outputs for tasks 5 (a, b, c) and task 6 are now available on the Moodle. Hope this helpsSaeid\n"}, {"subject": "Lecture 20.", "time": "Monday, 16 November 2020, 11:30 AM", "context": "\nDear allI'm back, and going to deliver the remaining parts including deadlocks and file systems until the end of this semester. I updated lecture 20 slides with the quizzes and new deadlock examples. The examples explain further how deadlock detection algorithm works. Please use the new slides.hope this helpsSaeid\n"}, {"subject": "OSC Coursework ", "time": "Sunday, 15 November 2020, 11:36 AM", "context": "\nDear allOSC coursework is now released on the Moodle. This consists of two tasks focusing on process scheduling and publisher/consumer problem. Please carefully read the description to see all the required information of the tasks and submissions. Sample answers and required codes will be provided shortly.The deadline of this coursework is 14th December at 12:00 AM (china time). You *MUST* submit yours any time before the deadline. To avoid last minute conflicts and internet/platform problems, this is highly recommended to submit your coursework as soon as possible. If you have any question, please join our office hours.ThanksSaeid and Qian\n"}, {"subject": "Module schedule is updated. ", "time": "Thursday, 12 November 2020, 4:15 PM", "context": "\nDear allPlease see the module schedule updated here.Thanks Saeid\n"}, {"subject": "Early module feedback respond", "time": "Sunday, 8 November 2020, 9:48 PM", "context": "\nTo respond to comments on early module feedback, we are going to make the following changes:1. One additional hour is added to Thursday afternoon office hour, please check the moodle page for office hour detail.2. Exercises adding to slides.3. Lab solutions will be uploaded soon.Cheers,Qian Zhang\n"}, {"subject": "Saeid's Q/A resumes.", "time": "Monday, 2 November 2020, 11:41 PM", "context": "\nDear allTo inform you that, my office hours run until the end of semester as usual.I will be available in my office tomorrow (14:00-15:00) for Q/A. Please feel free to join me if you have any question from the previous lectures (except memory management which is by Qian).For the aboard students, I will be available online (tomorrow 15:00- 16:00) if you need help. Thanks Saeid\n"}, {"subject": "Feedback and announcement of OSC", "time": "Monday, 26 October 2020, 4:05 PM", "context": "\nHello everyone,Nice to see you today. As I said in the lecture, we will only have the Monday lecture session + lab session from this week to the end of this semester. Please refer to the schedule on the Moodle page.Up to now, it's already been more than one month since we started this semester.  We have gathered some feedback through different channels for this module. To follow up these comments:1. Here is some discontinuity due to the lecturer being away. As you may notice, we start wearing the remote mic during the lecture. Hope it helps. 2. The latest lab did not cover the latest material.We break the whole lab materials into different tasks with hierarchies, where later tasks are built upon the previous one. Tasks 1 & 2 are setting the context for later ones. We do hope you can pay attention to the exercise we provide and try to finish them in time. Otherwise, it will be more and more difficult for later tasks. Of course, you are always welcome to ask questions during the lab or office hours.3. The lecture being taught too fast.It is never enough to use only 2-3 lecture hours each week to learn a subject. We suggest you preview and review the slides before and after the class each week. We'd love to see that you come to class with questions and try to find those answers within the class. Besides, every subject of OSC has interconnections between one another, like process and memory, process and concurrency, etc.. It will be more and more difficult for you if there are uncleared contents or unsolved questions in previous weeks. We are providing after class exercise for you to check if you understand the content. Again, you are always welcome to ask questions. Thanks for your attention. The feedback channel is always open, and you are welcome to provide comments.Dr Qian Zhang\n"}, {"subject": "Office hours canclled for two weeks.", "time": "Sunday, 18 October 2020, 1:55 PM", "context": "\nDear allDue to an urgent issue, I wont be able to join you in Q/A office hours (both in-person and online) for two weeks (20th and 27th Sep.).Please feel free to email me, if you have any questions on teachings/labs or need help. I will manage to reply you ASAP.However, lectures and labs run as usual on Mondays, Tuesdays and Wednesdays.See you soon. Saeid\n"}, {"subject": "An update on Lab's guide.", "time": "Wednesday, 14 October 2020, 1:21 PM", "context": "\nDear allAn update made on the lab's guide, with the instructions to mount the home directory onto your laptop for both windows and mac/linux users. This is available on Moodle now.Hope this helpsSaeid\n"}, {"subject": "OSC labs", "time": "Tuesday, 13 October 2020, 1:29 PM", "context": "\nDear allTo remind you, our OSC labs get kicked off this Wednesday 2020.10.14, at 9-11 in PMB 432.Please have a look at the lab materials and guidance, available on Moodle, and learn how to setup the programming environment, and/or connect to CS linux server. The lab worksheet is also available there, this shows how OSC labs are going to be organised. Please feel free to bring in your laptops.Student who are still away, please try to get connected using UNNC VPN. Thanks see you tomorrow Saeid\n"}, {"subject": "An update on Lecture 4, 5", "time": "Monday, 5 October 2020, 11:48 AM", "context": "\nDear allHerewith is the update on lecture 4,5:1- Slide 29, Scheduling algorithms -Round Robin:\n\n\n\n\"E.g., a high throughput is achieved with a large time slice (e.g.\r\n1000ms) leads to increased response time.\" This means, response time is increased when processes utilise a longer time slice (1000). This is because the processes should wait for a longer time to take CPU for the first execution, and then get included for response time calculation. However, throughput is increased as the process get a better chance (and longer/sufficient time) to get finished when time slices are large. \n\n\n\n2- slide 27, quiz:\n\n\n\n\n\n\n\"Which one is True in process scheduling?\r\n\r\n\t\t\t\t\t\tA) Preemptive scheduling results in CPU monopolizing.\r\nB) Non-preemptive scheduling works well on batch systems.\r\nC) Frequent context-switch results in increased response time.\r\nD) Turnaround time is positively correlated with system throughput.\"\n\n\n\nTo explain why D is not true:If Turnaround time is increased, system throughput is reduced. This is because if the processes get finished for longer time, the number of finishing processes over a time unit (e.g. one hour) is reduced. Hence, Turnaround time is negatively correlated with system throughput!\n\n\n\nPlease find the updated/corrected slides on Moodle, for Lecture 4,5.Saeid\n"}, {"subject": "Lecture on Monday 2020.10.05", "time": "Saturday, 3 October 2020, 12:59 PM", "context": "\nDear allI hope you all had a great holiday, and back campus fresh. To inform you, we will resume the lectures, this Monday 2020.10.05, 9:00-11:00, DB-A05.Looking forward to see you all there.Have a good weekend Saeid\n"}, {"subject": "Welcome ", "time": "Friday, 18 September 2020, 3:07 PM", "context": "\nDear allWelcome to OSC module. This is good to see you at UNNC for the new semester. We will kick off this module on Monday 2020-09-21 at 9:00 AM, DB-A05. According to our schedule, OSC lectures will be on Mondays 9-11 and Tuesdays 10-11. Yet, we will have Labs on Wednesday 9-11, starting from week 4. You can find the full schedule on the Moodle page. Teaching materials will be available 24 hours before each session on Moodle. You can have a look and get ready for the lecture then. For the students who are still stranded abroad, this confirms that the lectures will be recorded and can be accessed on Moodle shortly after each teaching session. Please feel free to post your feedback, question and/or request on Moodle. Plus, you are welcome to come and see us during our office hours (Only Saeid is available until 6th Nov.). You can email us to make an appointment if need other timeslots. Have a great weekend.See you on MondaySaeid&Qian\n"}]